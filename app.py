import pandas as pd
from datetime import datetime
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.styles import Font, PatternFill, Alignment
from openpyxl.chart import PieChart, BarChart, Reference
from openpyxl.styles.differential import DifferentialStyle
from openpyxl.formatting.rule import Rule
import os
import logging
import subprocess
from pathlib import Path
import re  # –î–æ–±–∞–≤–ª–µ–Ω–æ: –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª –∏–º–ø–æ—Ä—Ç re
from difflib import SequenceMatcher  # –î–æ–±–∞–≤–ª–µ–Ω–æ: –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª –∏–º–ø–æ—Ä—Ç
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.corpus import stopwords
from fuzzywuzzy import fuzz

# Download stopwords if not already downloaded
try:
    stopwords.words('russian')
except LookupError:
    nltk.download('stopwords')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    filename='processing.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def extract_phone_numbers(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤"""
    if pd.isna(text):
        return []

    text_str = str(text)

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤
    phone_patterns = [
        r'\+7\s?\(?\d{3}\)?\s?\d{3}[\s-]?\d{2}[\s-]?\d{2}',  # +7 —Ñ–æ—Ä–º–∞—Ç—ã
        r'8\s?\(?\d{3}\)?\s?\d{3}[\s-]?\d{2}[\s-]?\d{2}',   # 8 —Ñ–æ—Ä–º–∞—Ç—ã
        r'\(\d{3}\)\s?\d{3}[\s-]?\d{2}[\s-]?\d{2}',         # (999) 999-99-99
        r'\d{3}[\s-]?\d{2}[\s-]?\d{2}[\s-]?\d{2}',          # 999-99-99-99
        r'\d{3}[\s-]?\d{3}[\s-]?\d{2}[\s-]?\d{2}',          # 999-999-99-99
    ]

    phones = []
    for pattern in phone_patterns:
        matches = re.findall(pattern, text_str)
        for match in matches:
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–º–µ—Ä–∞ –∫ —Ñ–æ—Ä–º–∞—Ç—É +7XXXXXXXXXX
            clean_phone = re.sub(r'[\s\(\)\-+]', '', match)
            if clean_phone.startswith('8') and len(clean_phone) == 11:
                clean_phone = '+7' + clean_phone[1:]
            elif clean_phone.startswith('7') and len(clean_phone) == 11:
                clean_phone = '+7' + clean_phone[1:]
            elif len(clean_phone) == 10:
                clean_phone = '+7' + clean_phone

            if len(clean_phone) == 12 and clean_phone.startswith('+7'):
                phones.append(clean_phone)

    return list(set(phones))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã

def similar_text(text1, text2, threshold=0.85):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º –≤–æ–∑–º–æ–∂–Ω—ã—Ö –æ–ø–µ—á–∞—Ç–æ–∫"""
    if pd.isna(text1) or pd.isna(text2):
        return False
    return SequenceMatcher(None, str(text1).lower(), str(text2).lower()).ratio() >= threshold

def similar_phones(phones1, phones2):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–æ–≤ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤"""
    if not phones1 or not phones2:
        return False

    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–æ–º–µ—Ä–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
    common_phones = set(phones1) & set(phones2)
    return len(common_phones) > 0

def extract_address(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ–±—Ä–∞—â–µ–Ω–∏—è"""
    if pd.isna(text):
        return '–∞–¥—Ä–µ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω'

    text_str = str(text).lower()

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–¥—Ä–µ—Å–∞
    address_patterns = [
        r'(—É–ª\.?|—É–ª–∏—Ü–∞|–ø—Ä–æ—Å–ø|–ø—Ä\.|–ø—Ä–æ—Å–ø–µ–∫—Ç|–ø–µ—Ä\.|–ø–µ—Ä–µ—É–ª–æ–∫|—à–æ—Å—Å–µ|–Ω–∞–±\.|–Ω–∞–±–µ—Ä–µ–∂–Ω–∞—è)[\s\w\d.-]+',
        r'–¥\.?\s*\d+',
        r'–¥–æ–º\.?\s*\d+',
        r'–∫–≤\.?\s*\d+',
        r'–∫–≤–∞—Ä—Ç–∏—Ä–∞\.?\s*\d+',
        r'–∫–æ—Ä–ø\.?\s*\d+',
        r'—Å—Ç—Ä–æ–µ–Ω\.?\s*\d+',
        r'–º–∏–∫—Ä–æ—Ä–∞–π–æ–Ω\.?\s*[\w\d]+',
        r'—Ä-–Ω\.?\s*[\w\d]+'
    ]

    address_parts = []
    for pattern in address_patterns:
        matches = re.findall(pattern, text_str, re.IGNORECASE)
        for match in matches:
            clean_match = re.sub(r'\s+', ' ', match).strip()
            address_parts.append(clean_match)

    unique_parts = []
    for part in address_parts:
        if part not in unique_parts:
            unique_parts.append(part)

    return ' '.join(unique_parts) if unique_parts else '–∞–¥—Ä–µ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω'

def categorize_consumer(consumer_name, appeal_text):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è"""
    if pd.isna(consumer_name):
        consumer_name = ''
    if pd.isna(appeal_text):
        appeal_text = ''

    consumer_str = str(consumer_name).lower()
    appeal_str = str(appeal_text).lower()

    legal_keywords = [
        '–æ–æ–æ', '–∑–∞–æ', '–æ–∞–æ', '–∞–æ', '–ø–∞–æ', '–Ω–∞–æ', '–º–∫—É', '–º–∫—É–ø', '–º—É–ø', '–≥–±—É',
        '–º–±—É', '–º–±–æ—É', '–º–∞–¥–æ—É', '–≥–∫–æ—É', '—É—á—Ä–µ–∂–¥–µ–Ω–∏–µ', '–ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ', '–∫–æ–º–ø–∞–Ω–∏—è',
        '—Ñ–∏—Ä–º–∞', '–∫–æ—Ä–ø—É—Å', '—Å—Ç—Ä–æ–π', '—Ä–µ–º–æ–Ω—Ç', '—Å–µ—Ä–≤–∏—Å', '—Ü–µ–Ω—Ç—Ä', '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ',
        '—Ö–æ–ª–¥–∏–Ω–≥', '–≥—Ä—É–ø–ø', '—Ç–æ—Ä–≥', '–ø—Ä–æ–º', '–∑–∞–≤–æ–¥', '—Ñ–∞–±—Ä–∏–∫–∞', '–∫–æ–º–±–∏–Ω–∞—Ç',
        '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è', '–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ', '–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç'
    ]

    for keyword in legal_keywords:
        if keyword in consumer_str:
            return '–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ'

    for keyword in legal_keywords:
        if keyword in appeal_str:
            return '–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ'

    if consumer_str.strip() and appeal_str.strip():
        return '–§–∏–∑–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ'

    return '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'

def get_file_path():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤–≤–æ–¥"""
    try:
        file_path = input("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É Excel —Å –æ–±—Ä–∞—â–µ–Ω–∏—è–º–∏: ").strip()
        
        if not file_path:
            print("–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω. –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            return None
        
        if not os.path.exists(file_path):
            print(f"–§–∞–π–ª '{file_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return None
            
        print(f"–§–∞–π–ª '{file_path}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
        return file_path
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
        print(f"\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
        return None

def load_data(file_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        print("\n–≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        df = pd.read_excel(file_path)
        print(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape}")
        print(f"–°—Ç–æ–ª–±—Ü—ã –≤ —Ñ–∞–π–ª–µ: {list(df.columns)}")
        logging.info(f"–£—Å–ø–µ—à–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {file_path}")
        logging.info(f"–°—Ç–æ–ª–±—Ü—ã –≤ —Ñ–∞–π–ª–µ: {list(df.columns)}")

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å –¥–∞—Ç–æ–π
        date_columns = []
        for col in df.columns:
            if any(keyword in str(col).lower() for keyword in ['–¥–∞—Ç–∞', 'date', '—Å–æ–∑–¥–∞–Ω', 'created']):
                date_columns.append(col)

        if date_columns:
            print(f"–ù–∞–π–¥–µ–Ω—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Å –¥–∞—Ç–æ–π: {date_columns}")
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Å—Ç–æ–ª–±–µ—Ü
            date_column = date_columns[0]
            df[date_column] = pd.to_datetime(df[date_column], errors='coerce')
            print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π: '{date_column}'")
        else:
            print("‚ö†Ô∏è –°—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π –Ω–µ –Ω–∞–π–¥–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")

        return df
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        print(f"\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
        return None

# ... (–æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –∫—Ä–æ–º–µ download_file)

def download_file(file_path):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ files.download)"""
    try:
        # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–∏–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        print(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ø–æ –ø—É—Ç–∏: {os.path.abspath(file_path)}")
        
        # –ï—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –≤ —Å—Ä–µ–¥–µ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ–π –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–æ–≤
        try:
            from google.colab import files as colab_files
            colab_files.download(file_path)
            print(f"–§–∞–π–ª '{file_path}' –∑–∞–≥—Ä—É–∂–µ–Ω —á–µ—Ä–µ–∑ Colab.")
        except ImportError:
            print("–î–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–¥ –≤ Google Colab")
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")

# –í —Ñ—É–Ω–∫—Ü–∏–∏ generate_report_final –∑–∞–º–µ–Ω–∏—Ç–µ –≤—ã–∑–æ–≤ files.download –Ω–∞ download_file
def generate_report_final(original_df, unique_df, duplicates_detailed, work_df, column_mapping):
    """Creation of the final report with enhanced statistics and detailed duplicate analysis."""
    try:
        print("\n–≠—Ç–∞–ø 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")

        output_path = Path('–æ—Ç—á–µ—Ç_–æ–±—Ä–∞—â–µ–Ω–∏–π_—Ñ–∏–Ω–∞–ª.xlsx')

        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # ... (–æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ —Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)

        print(f"\nüìä –û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ø–æ –ø—É—Ç–∏: {output_path.absolute()}")
        print(f"üìã –õ–∏—Å—Ç—ã –æ—Ç—á–µ—Ç–∞:")
        print(f"   1. –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - {len(original_df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"   2. –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ - {len(unique_df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"   3. –î—É–±–ª–∏–∫–∞—Ç—ã - {len(duplicates_detailed)} –∑–∞–ø–∏—Å–µ–π")
        print(f"   4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ - –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        print(f"   5. –ì—Ä–∞—Ñ–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
        if len(duplicates_detailed) > 0:
             print(f"   6. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ - –ø–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≥—Ä—É–ø–ø–∞–º")

        logging.info(f"–£—Å–ø–µ—à–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞: {output_path}")

        # –ó–∞–º–µ–Ω–∏—Ç–µ files.download –Ω–∞ download_file
        download_file(output_path)
        print(f"\n‚¨áÔ∏è –§–∞–π–ª '{output_path.name}' –≥–æ—Ç–æ–≤ –∫ –∑–∞–≥—Ä—É–∑–∫–µ.")

        return True

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
        return False

# ... (–æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)

# –£–±–µ—Ä–∏—Ç–µ –≤—ã–∑–æ–≤ main_final() –≤ –∫–æ–Ω—Ü–µ, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—É—Å–∫
if __name__ == "__main__":
    main_final()
