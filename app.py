# app.py
"""
Streamlit-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π (—É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å / –¥—É–±–ª–∏–∫–∞—Ç—ã).
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ ./process_data/ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ ./process_data/–æ—Ç—á–µ—Ç_–æ–±—Ä–∞—â–µ–Ω–∏–π_<–∏–º—è>.xlsx

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è (–ø—Ä–∏–º–µ—Ä):
pip install streamlit pandas openpyxl scikit-learn nltk fuzzywuzzy python-levenshtein plotly
"""

import streamlit as st
import pandas as pd
import re
from pathlib import Path
from difflib import SequenceMatcher
from fuzzywuzzy import fuzz
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.corpus import stopwords
import plotly.express as px
import io
import datetime

# --- Ensure Russian stopwords are available ---
try:
    stopwords.words('russian')
except LookupError:
    nltk.download('stopwords')

# --- Utility functions (extracted and simplified) ---
def extract_phone_numbers(text):
    """–ù–∞–π—Ç–∏ –Ω–æ–º–µ—Ä–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫ —Ñ–æ—Ä–º–∞—Ç—É +7XXXXXXXXXX"""
    if pd.isna(text):
        return []
    text_str = str(text)
    # –ø—Ä–æ—Å—Ç–æ–π –æ–±—â–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
    matches = re.findall(r'(?:\+7|8)?\s*\(?\d{3}\)?[\s-]?\d{3}[\s-]?\d{2}[\s-]?\d{2}', text_str)
    normalized = []
    for m in matches:
        digits = re.sub(r'\D', '', m)
        if len(digits) == 11 and digits.startswith('8'):
            digits = '7' + digits[1:]
        if len(digits) == 11 and digits.startswith('7'):
            normalized.append('+' + digits)
        elif len(digits) == 10:
            normalized.append('+7' + digits)
    return list(set(normalized))

def tfidf_similarity(text1, text2):
    """TF-IDF cosine similarity (0..1)"""
    if pd.isna(text1) or pd.isna(text2):
        return 0.0
    s1 = str(text1).lower()
    s2 = str(text2).lower()
    try:
        vec = TfidfVectorizer(stop_words=stopwords.words('russian'))
        tfidf = vec.fit_transform([s1, s2])
        sim = cosine_similarity(tfidf)[0, 1]
        if pd.isna(sim):
            return 0.0
        return float(sim)
    except Exception:
        return 0.0

def fuzzy_similar_names(n1, n2, threshold=80):
    if pd.isna(n1) or pd.isna(n2):
        return False
    try:
        score = fuzz.token_set_ratio(str(n1), str(n2))
        return score >= threshold
    except Exception:
        return False

def fuzzy_similar_addresses(a1, a2, threshold=75):
    if pd.isna(a1) or pd.isna(a2):
        return False
    try:
        score = fuzz.token_sort_ratio(str(a1), str(a2))
        return score >= threshold
    except Exception:
        return False

# --- Data loading & validation ---
def load_data(file_path: str) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å Excel-—Ñ–∞–π–ª –≤ DataFrame –∏ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –ø—Ä–∏–≤–µ—Å—Ç–∏ –¥–∞—Ç—ã"""
    df = pd.read_excel(file_path)
    # –ø—Ä–æ–±—É–µ–º –ø—Ä–∏–≤–µ—Å—Ç–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü –¥–∞—Ç—ã
    for col in df.columns:
        if any(k in str(col).lower() for k in ['–¥–∞—Ç–∞', 'date', '—Å–æ–∑–¥–∞–Ω', 'created']):
            try:
                df[col] = pd.to_datetime(df[col], errors='coerce')
            except Exception:
                pass
            break
    return df

def detect_key_columns(df: pd.DataFrame):
    """–ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–æ–ª–±—Ü—ã: name, text, address"""
    name_col = None
    text_col = None
    addr_col = None
    for c in df.columns:
        lc = str(c).lower()
        if not name_col and any(k in lc for k in ['–ø–æ—Ç—Ä–µ–±', '–∫–ª–∏–µ–Ω—Ç', '–∑–∞—è–≤–∏—Ç–µ–ª', '–∏–º—è', '—Ñ–∞–º–∏–ª–∏—è', '–∫–æ–Ω—Ç–∞–∫—Ç']):
            name_col = c
        if not text_col and any(k in lc for k in ['—Ç–µ–∫—Å—Ç', '–æ–±—Ä–∞—â', '–æ–ø–∏—Å–∞–Ω', '–∂–∞–ª–æ–±', '—Å–æ–æ–±—â–µ–Ω–∏']):
            text_col = c
        if not addr_col and any(k in lc for k in ['–∞–¥—Ä–µ—Å', '–º–µ—Å—Ç–æ–ø–æ–ª–æ–∂', '–æ–±—ä–µ–∫—Ç']):
            addr_col = c
    # fallbacks
    if text_col is None:
        # –≤–æ–∑—å–º–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü
        for c in df.columns:
            if df[c].dtype == object:
                text_col = c
                break
    return {'name': name_col, 'text': text_col, 'address': addr_col}

# --- Core algorithm: –ø–æ–∏—Å–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ---
def find_unique_and_duplicates_weighted(df: pd.DataFrame,
                                        tfidf_threshold=0.45,
                                        name_fuzzy_threshold=85,
                                        address_fuzzy_threshold=75,
                                        score_threshold=10,
                                        criteria_weights=None):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç unique_df, duplicates_detailed, work_df.
    –ê–ª–≥–æ—Ä–∏—Ç–º –ø—Ä–æ—Å—Ç: –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –ø–æ—Å–ª–µ–¥—É—é—â–∏–º–∏ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.
    """
    if criteria_weights is None:
        criteria_weights = {
            'phones': 12,
            'text': 8,
            'name': 5,
            'address': 4
        }

    work_df = df.copy().reset_index(drop=True)
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è (–µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç, —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç—ã–µ)
    cols = detect_key_columns(work_df)
    name_col = cols['name']
    text_col = cols['text']
    address_col = cols['address']

    work_df['__name'] = work_df[name_col] if name_col else ''
    work_df['__text'] = work_df[text_col] if text_col else ''
    work_df['__address'] = work_df[address_col] if address_col else ''

    # phones: –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫ (concat)
    work_df['__phones'] = work_df.apply(lambda r: extract_phone_numbers(' '.join([str(x) for x in r.values if pd.notna(x)])), axis=1)

    work_df['–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'] = ''
    work_df['–ö—Ä–∏—Ç–µ—Ä–∏–π —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è'] = ''
    work_df['–°—É–º–º–∞—Ä–Ω—ã–π –±–∞–ª–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è'] = 0.0

    n = len(work_df)
    used = set()
    group_id = 0

    # –ø—Ä–æ—Å—Ç–æ–π O(n^2) –ø—Ä–æ—Ö–æ–¥
    for i in range(n):
        if i in used:
            continue
        group_id += 1
        work_df.at[i, '–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'] = str(group_id)
        base_name = work_df.at[i, '__name']
        base_text = work_df.at[i, '__text']
        base_addr = work_df.at[i, '__address']
        base_phones = work_df.at[i, '__phones']

        for j in range(i+1, n):
            if j in used:
                continue
            score = 0
            criteria = []

            # —Ç–µ–ª–µ—Ñ–æ–Ω—ã
            phones_j = work_df.at[j, '__phones']
            if base_phones and phones_j and set(base_phones) & set(phones_j):
                score += criteria_weights['phones']
                criteria.append('—Ç–µ–ª–µ—Ñ–æ–Ω')

            # —Ç–µ–∫—Å—Ç TF-IDF
            if tfidf_similarity(base_text, work_df.at[j, '__text']) >= tfidf_threshold:
                score += criteria_weights['text']
                criteria.append('—Ç–µ–∫—Å—Ç')

            # –∏–º—è fuzzy
            if fuzzy_similar_names(base_name, work_df.at[j, '__name'], threshold=name_fuzzy_threshold):
                score += criteria_weights['name']
                criteria.append('–∏–º—è')

            # –∞–¥—Ä–µ—Å fuzzy
            if fuzzy_similar_addresses(base_addr, work_df.at[j, '__address'], threshold=address_fuzzy_threshold):
                score += criteria_weights['address']
                criteria.append('–∞–¥—Ä–µ—Å')

            if score >= score_threshold:
                used.add(j)
                work_df.at[j, '–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'] = str(group_id)
                work_df.at[j, '–ö—Ä–∏—Ç–µ—Ä–∏–π —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è'] = ', '.join(criteria)
                work_df.at[j, '–°—É–º–º–∞—Ä–Ω—ã–π –±–∞–ª–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è'] = score

    duplicates_detailed = work_df[work_df['–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'] != ''].copy()
    # –ü–æ–º–µ—Ç–∏–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ: —Ç–µ, –∫—Ç–æ –æ–∫–∞–∑–∞–ª—Å—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –≤ —Å–≤–æ–µ–π –≥—Ä—É–ø–ø–µ
    group_sizes = duplicates_detailed['–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'].value_counts()
    singleton_groups = group_sizes[group_sizes == 1].index.tolist()
    # —Å—Ç—Ä–æ–∫–∏ —Å –≥—Ä—É–ø–ø–∞–º–∏ singleton (—Ç.–µ. —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç—ã) –Ω–∞–¥–æ –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ
    duplicates_mask = work_df['–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'].isin(group_sizes.index[group_sizes > 1])
    duplicates_df = work_df[duplicates_mask].copy()
    unique_df = work_df[~duplicates_mask].copy()

    # –æ—á–∏—Å—Ç–∏–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ –≤—ã–¥–∞—á–∏ (–æ—Å—Ç–∞–≤–∏–º, –Ω–æ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å)
    return unique_df.reset_index(drop=True), duplicates_df.reset_index(drop=True), work_df.reset_index(drop=True)

# --- Report generation: –∑–∞–ø–∏—Å–∞—Ç—å Excel —Å –ª–∏—Å—Ç–∞–º–∏ '–ò—Å—Ö–æ–¥–Ω—ã–µ', '–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ', '–î—É–±–ª–∏–∫–∞—Ç—ã', '–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞' ---
def generate_report(output_path: Path, original_df: pd.DataFrame, unique_df: pd.DataFrame, duplicates_df: pd.DataFrame):
    try:
        stats = []
        total = len(original_df)
        uniq = len(unique_df)
        dups = len(duplicates_df)
        stats.append({'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–í—Å–µ–≥–æ –æ–±—Ä–∞—â–µ–Ω–∏–π', '–ó–Ω–∞—á–µ–Ω–∏–µ': total})
        stats.append({'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—Ä–∞—â–µ–Ω–∏–π', '–ó–Ω–∞—á–µ–Ω–∏–µ': uniq})
        stats.append({'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–î—É–±–ª–∏–∫–∞—Ç–æ–≤ (–∑–∞–ø–∏—Å–µ–π)', '–ó–Ω–∞—á–µ–Ω–∏–µ': dups})
        stats.append({'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–î–æ–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (%)', '–ó–Ω–∞—á–µ–Ω–∏–µ': f"{(dups/total*100):.1f}%" if total else "0%"})

        stats_df = pd.DataFrame(stats)

        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            original_df.to_excel(writer, sheet_name='–ò—Å—Ö–æ–¥–Ω—ã–µ', index=False)
            unique_df.to_excel(writer, sheet_name='–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ', index=False)
            duplicates_df.to_excel(writer, sheet_name='–î—É–±–ª–∏–∫–∞—Ç—ã', index=False)
            stats_df.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)
        return True, None
    except Exception as e:
        return False, str(e)

# --- Streamlit UI ---
st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –æ–±—Ä–∞—â–µ–Ω–∏–π", layout="wide")
st.title("üìä –ê–Ω–∞–ª–∏–∑ –æ–±—Ä–∞—â–µ–Ω–∏–π ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª. –§–∞–π–ª –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ `process_data/`. –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç.")

# ensure folders
PROCESS_DIR = Path("./process_data")
PROCESS_DIR.mkdir(parents=True, exist_ok=True)

uploaded = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ Excel-—Ñ–∞–π–ª", type=["xlsx", "xls"])
if uploaded is None:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞.")
else:
    # save uploaded file
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    input_path = PROCESS_DIR / f"{timestamp}_{uploaded.name}"
    with open(input_path, "wb") as f:
        f.write(uploaded.getbuffer())
    st.success(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: `{input_path}`")

    # load and preview
    try:
        df = load_data(str(input_path))
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        st.stop()

    st.subheader("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä (–ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏)")
    st.dataframe(df.head(10))

    # Allow user to tune thresholds (optional)
    with st.expander("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)"):
        tfidf_thr = st.slider("TF-IDF threshold (—Ç–µ–∫—Å—Ç)", 0.0, 1.0, 0.45, 0.01)
        name_thr = st.slider("Fuzzy –¥–ª—è –∏–º–µ–Ω–∏ (0-100)", 50, 100, 85, 1)
        addr_thr = st.slider("Fuzzy –¥–ª—è –∞–¥—Ä–µ—Å–∞ (0-100)", 50, 100, 75, 1)
        score_thr = st.slider("–ü–æ—Ä–æ–≥ —Å—É–º–º–∞—Ä–Ω–æ–≥–æ –±–∞–ª–ª–∞", 1, 50, 10, 1)

    if st.button("‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É"):
        with st.spinner("–ò–¥—ë—Ç –ø–æ–∏—Å–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤..."):
            try:
                unique_df, duplicates_df, work_df = find_unique_and_duplicates_weighted(
                    df,
                    tfidf_threshold=tfidf_thr,
                    name_fuzzy_threshold=name_thr,
                    address_fuzzy_threshold=addr_thr,
                    score_threshold=score_thr
                )

                # stats
                total = len(df)
                uniq = len(unique_df)
                dups = len(duplicates_df)
                st.subheader("–ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("–í—Å–µ–≥–æ –æ–±—Ä–∞—â–µ–Ω–∏–π", total)
                c2.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö", uniq)
                c3.metric("–î—É–±–ª–∏–∫–∞—Ç–æ–≤", dups)
                c4.metric("–î–æ–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤", f"{(dups/total*100):.1f}%" if total else "0%")

                # show small samples
                st.subheader("–ü—Ä–∏–º–µ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
                st.dataframe(unique_df.head(10))

                st.subheader("–ü—Ä–∏–º–µ—Ä –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
                st.dataframe(duplicates_df.head(20))

                # Charts: –ø–æ –º–µ—Å—è—Ü–∞–º –∏ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
                # detect date column
                date_col = next((c for c in df.columns if "–¥–∞—Ç–∞" in str(c).lower() or "date" in str(c).lower()), None)
                if date_col:
                    try:
                        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                        monthly = df[df[date_col].notna()][date_col].dt.to_period('M').value_counts().sort_index()
                        if not monthly.empty:
                            fig1 = px.bar(x=monthly.index.astype(str), y=monthly.values,
                                          labels={'x': '–ú–µ—Å—è—Ü', 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'},
                                          title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—Ä–∞—â–µ–Ω–∏–π –ø–æ –º–µ—Å—è—Ü–∞–º")
                            st.plotly_chart(fig1, use_container_width=True)

                        # days of week
                        valid = df[df[date_col].notna()].copy()
                        # day_name in Russian may require locale; use english names then map
                        valid['__dow_en'] = valid[date_col].dt.day_name()
                        dow_map = {
                            'Monday': '–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', 'Tuesday': '–í—Ç–æ—Ä–Ω–∏–∫', 'Wednesday': '–°—Ä–µ–¥–∞',
                            'Thursday': '–ß–µ—Ç–≤–µ—Ä–≥', 'Friday': '–ü—è—Ç–Ω–∏—Ü–∞', 'Saturday': '–°—É–±–±–æ—Ç–∞', 'Sunday': '–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ'
                        }
                        valid['–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏'] = valid['__dow_en'].map(dow_map)
                        day_stats = valid['–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏'].value_counts().reindex(
                            ['–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫','–í—Ç–æ—Ä–Ω–∏–∫','–°—Ä–µ–¥–∞','–ß–µ—Ç–≤–µ—Ä–≥','–ü—è—Ç–Ω–∏—Ü–∞','–°—É–±–±–æ—Ç–∞','–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ']
                        ).fillna(0)
                        if day_stats.sum() > 0:
                            fig2 = px.bar(x=day_stats.index, y=day_stats.values,
                                          labels={'x': '–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏', 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'},
                                          title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—Ä–∞—â–µ–Ω–∏–π –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏")
                            st.plotly_chart(fig2, use_container_width=True)
                    except Exception as e:
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É: {e}")

                # category visualization if present
                # try find category column
                cat_col = next((c for c in df.columns if '–∫–∞—Ç–µ–≥' in str(c).lower() or '—Ç–∏–ø' in str(c).lower()), None)
                if cat_col:
                    cat_stats = df[cat_col].fillna('–ù–µ —É–∫–∞–∑–∞–Ω–æ').value_counts()
                    if not cat_stats.empty:
                        fig3 = px.pie(values=cat_stats.values, names=cat_stats.index, title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
                        st.plotly_chart(fig3, use_container_width=True)

                # Save report
                out_name = f"–æ—Ç—á–µ—Ç_–æ–±—Ä–∞—â–µ–Ω–∏–π_{timestamp}.xlsx"
                out_path = PROCESS_DIR / out_name
                ok, err = generate_report(out_path, df, unique_df, duplicates_df)
                if ok:
                    st.success(f"–û—Ç—á—ë—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω: `{out_path}`")
                    # provide download
                    with open(out_path, "rb") as f:
                        btn = st.download_button(
                            label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç (Excel)",
                            data=f,
                            file_name=out_path.name,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                else:
                    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç: {err}")

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
