# app.py
"""
Streamlit-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π (—É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å / –¥—É–±–ª–∏–∫–∞—Ç—ã).
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ ./process_data/ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ ./process_data/–æ—Ç—á–µ—Ç_–æ–±—Ä–∞—â–µ–Ω–∏–π_<–∏–º—è>.xlsx

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è (–ø—Ä–∏–º–µ—Ä):
pip install streamlit pandas openpyxl scikit-learn nltk rapidfuzz plotly
"""

import streamlit as st
import pandas as pd
import re
from pathlib import Path
from rapidfuzz import fuzz
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.corpus import stopwords
import plotly.express as px
import datetime

# --- Ensure Russian stopwords are available ---
try:
    stopwords.words('russian')
except LookupError:
    nltk.download('stopwords')

# --- Utility functions ---
def extract_phone_numbers(text):
    """–ù–∞–π—Ç–∏ –Ω–æ–º–µ—Ä–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫ —Ñ–æ—Ä–º–∞—Ç—É +7XXXXXXXXXX"""
    if pd.isna(text):
        return []
    text_str = str(text)
    matches = re.findall(r'(?:\+7|8)?\s*\(?\d{3}\)?[\s-]?\d{3}[\s-]?\d{2}[\s-]?\d{2}', text_str)
    normalized = []
    for m in matches:
        digits = re.sub(r'\D', '', m)
        if len(digits) == 11 and digits.startswith('8'):
            digits = '7' + digits[1:]
        if len(digits) == 11 and digits.startswith('7'):
            normalized.append('+' + digits)
        elif len(digits) == 10:
            normalized.append('+7' + digits)
    return list(set(normalized))

def tfidf_similarity(text1, text2):
    """TF-IDF cosine similarity (0..1)"""
    if pd.isna(text1) or pd.isna(text2):
        return 0.0
    s1 = str(text1).lower()
    s2 = str(text2).lower()
    try:
        vec = TfidfVectorizer(stop_words=stopwords.words('russian'))
        tfidf = vec.fit_transform([s1, s2])
        sim = cosine_similarity(tfidf)[0, 1]
        return float(sim) if not pd.isna(sim) else 0.0
    except Exception:
        return 0.0

def fuzzy_similar_names(n1, n2, threshold=80):
    if pd.isna(n1) or pd.isna(n2):
        return False
    score = fuzz.token_set_ratio(str(n1), str(n2))
    return score >= threshold

def fuzzy_similar_addresses(a1, a2, threshold=75):
    if pd.isna(a1) or pd.isna(a2):
        return False
    score = fuzz.token_sort_ratio(str(a1), str(a2))
    return score >= threshold

# --- Data loading & validation ---
def load_data(file_path: str) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å Excel-—Ñ–∞–π–ª"""
    df = pd.read_excel(file_path)
    # –ø—Ä–æ–±—É–µ–º –ø—Ä–∏–≤–µ—Å—Ç–∏ —Å—Ç–æ–ª–±—Ü—ã –¥–∞—Ç
    for col in df.columns:
        if any(k in str(col).lower() for k in ['–¥–∞—Ç–∞', 'date', '—Å–æ–∑–¥–∞–Ω', 'created']):
            df[col] = pd.to_datetime(df[col], errors='coerce')
            break
    return df

def detect_key_columns(df: pd.DataFrame):
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å name/text/address"""
    name_col, text_col, addr_col = None, None, None
    for c in df.columns:
        lc = str(c).lower()
        if not name_col and any(k in lc for k in ['–ø–æ—Ç—Ä–µ–±', '–∫–ª–∏–µ–Ω—Ç', '–∑–∞—è–≤–∏—Ç–µ–ª', '–∏–º—è']):
            name_col = c
        if not text_col and any(k in lc for k in ['—Ç–µ–∫—Å—Ç', '–æ–±—Ä–∞—â', '–æ–ø–∏—Å–∞–Ω', '–∂–∞–ª–æ–±', '—Å–æ–æ–±—â–µ–Ω']):
            text_col = c
        if not addr_col and any(k in lc for k in ['–∞–¥—Ä–µ—Å', '–º–µ—Å—Ç–æ–ø–æ–ª–æ–∂', '–æ–±—ä–µ–∫—Ç']):
            addr_col = c
    if text_col is None:  # fallback
        for c in df.columns:
            if df[c].dtype == object:
                text_col = c
                break
    return {'name': name_col, 'text': text_col, 'address': addr_col}

# --- Core algorithm ---
def find_unique_and_duplicates_weighted(df: pd.DataFrame,
                                        tfidf_threshold=0.45,
                                        name_fuzzy_threshold=85,
                                        address_fuzzy_threshold=75,
                                        score_threshold=10,
                                        criteria_weights=None):
    if criteria_weights is None:
        criteria_weights = {'phones': 12, 'text': 8, 'name': 5, 'address': 4}

    work_df = df.copy().reset_index(drop=True)
    cols = detect_key_columns(work_df)
    work_df['__name'] = work_df[cols['name']] if cols['name'] else ''
    work_df['__text'] = work_df[cols['text']] if cols['text'] else ''
    work_df['__address'] = work_df[cols['address']] if cols['address'] else ''
    work_df['__phones'] = work_df.apply(lambda r: extract_phone_numbers(' '.join([str(x) for x in r.values if pd.notna(x)])), axis=1)

    work_df['–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'] = ''
    work_df['–ö—Ä–∏—Ç–µ—Ä–∏–π —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è'] = ''
    work_df['–°—É–º–º–∞—Ä–Ω—ã–π –±–∞–ª–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è'] = 0.0

    used = set()
    group_id = 0
    n = len(work_df)

    for i in range(n):
        if i in used:
            continue
        group_id += 1
        work_df.at[i, '–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'] = str(group_id)
        for j in range(i+1, n):
            if j in used:
                continue
            score, criteria = 0, []
            if set(work_df.at[i, '__phones']) & set(work_df.at[j, '__phones']):
                score += criteria_weights['phones']; criteria.append('—Ç–µ–ª–µ—Ñ–æ–Ω')
            if tfidf_similarity(work_df.at[i, '__text'], work_df.at[j, '__text']) >= tfidf_threshold:
                score += criteria_weights['text']; criteria.append('—Ç–µ–∫—Å—Ç')
            if fuzzy_similar_names(work_df.at[i, '__name'], work_df.at[j, '__name'], name_fuzzy_threshold):
                score += criteria_weights['name']; criteria.append('–∏–º—è')
            if fuzzy_similar_addresses(work_df.at[i, '__address'], work_df.at[j, '__address'], address_fuzzy_threshold):
                score += criteria_weights['address']; criteria.append('–∞–¥—Ä–µ—Å')
            if score >= score_threshold:
                used.add(j)
                work_df.at[j, '–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'] = str(group_id)
                work_df.at[j, '–ö—Ä–∏—Ç–µ—Ä–∏–π —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è'] = ', '.join(criteria)
                work_df.at[j, '–°—É–º–º–∞—Ä–Ω—ã–π –±–∞–ª–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è'] = score

    group_sizes = work_df['–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'].value_counts()
    duplicates_df = work_df[work_df['–ì—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'].isin(group_sizes.index[group_sizes > 1])]
    unique_df = work_df[~work_df.index.isin(duplicates_df.index)]
    return unique_df, duplicates_df, work_df

def generate_report(output_path: Path, original_df, unique_df, duplicates_df):
    stats = [
        {'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–í—Å–µ–≥–æ –æ–±—Ä–∞—â–µ–Ω–∏–π', '–ó–Ω–∞—á–µ–Ω–∏–µ': len(original_df)},
        {'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—Ä–∞—â–µ–Ω–∏–π', '–ó–Ω–∞—á–µ–Ω–∏–µ': len(unique_df)},
        {'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–î—É–±–ª–∏–∫–∞—Ç–æ–≤ (–∑–∞–ø–∏—Å–µ–π)', '–ó–Ω–∞—á–µ–Ω–∏–µ': len(duplicates_df)},
        {'–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å': '–î–æ–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (%)',
         '–ó–Ω–∞—á–µ–Ω–∏–µ': f"{(len(duplicates_df)/len(original_df)*100):.1f}%" if len(original_df) else "0%"}
    ]
    with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
        original_df.to_excel(writer, sheet_name="–ò—Å—Ö–æ–¥–Ω—ã–µ", index=False)
        unique_df.to_excel(writer, sheet_name="–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ", index=False)
        duplicates_df.to_excel(writer, sheet_name="–î—É–±–ª–∏–∫–∞—Ç—ã", index=False)
        pd.DataFrame(stats).to_excel(writer, sheet_name="–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", index=False)

# --- Streamlit UI ---
st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –æ–±—Ä–∞—â–µ–Ω–∏–π", layout="wide")
st.title("üìä –ê–Ω–∞–ª–∏–∑ –æ–±—Ä–∞—â–µ–Ω–∏–π ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã")

PROCESS_DIR = Path("./process_data")
PROCESS_DIR.mkdir(parents=True, exist_ok=True)

uploaded = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ Excel-—Ñ–∞–π–ª", type=["xlsx", "xls"])
if uploaded:
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    input_path = PROCESS_DIR / f"{ts}_{uploaded.name}"
    with open(input_path, "wb") as f:
        f.write(uploaded.getbuffer())
    st.success(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {input_path}")

    df = load_data(str(input_path))
    st.subheader("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä")
    st.dataframe(df.head(10))

    if st.button("‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É"):
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞..."):
            unique_df, duplicates_df, work_df = find_unique_and_duplicates_weighted(df)
            total, uniq, dups = len(df), len(unique_df), len(duplicates_df)
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("–í—Å–µ–≥–æ", total)
            col2.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ", uniq)
            col3.metric("–î—É–±–ª–∏–∫–∞—Ç—ã", dups)
            col4.metric("–î–æ–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤", f"{dups/total*100:.1f}%" if total else "0%")

            st.subheader("–ü—Ä–∏–º–µ—Ä—ã —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö")
            st.dataframe(unique_df.head(10))
            st.subheader("–ü—Ä–∏–º–µ—Ä—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
            st.dataframe(duplicates_df.head(10))

            # --- –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ –º–µ—Å—è—Ü–∞–º –∏ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏ ---
            date_col = next((c for c in df.columns if "–¥–∞—Ç–∞" in c.lower() or "date" in c.lower()), None)
            if date_col:
                df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
                monthly = df[df[date_col].notna()][date_col].dt.to_period("M").value_counts().sort_index()
                if not monthly.empty:
                    st.plotly_chart(px.bar(x=monthly.index.astype(str), y=monthly.values,
                                           labels={"x":"–ú–µ—Å—è—Ü","y":"–ö–æ–ª-–≤–æ"},
                                           title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –º–µ—Å—è—Ü–∞–º"), use_container_width=True)
                dow_map = {"Monday":"–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫","Tuesday":"–í—Ç–æ—Ä–Ω–∏–∫","Wednesday":"–°—Ä–µ–¥–∞",
                           "Thursday":"–ß–µ—Ç–≤–µ—Ä–≥","Friday":"–ü—è—Ç–Ω–∏—Ü–∞","Saturday":"–°—É–±–±–æ—Ç–∞","Sunday":"–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"}
                df["–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏"] = df[date_col].dt.day_name().map(dow_map)
                day_stats = df["–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏"].value_counts().reindex(
                    ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫","–í—Ç–æ—Ä–Ω–∏–∫","–°—Ä–µ–¥–∞","–ß–µ—Ç–≤–µ—Ä–≥","–ü—è—Ç–Ω–∏—Ü–∞","–°—É–±–±–æ—Ç–∞","–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"]
                ).fillna(0)
                st.plotly_chart(px.bar(x=day_stats.index, y=day_stats.values,
                                       labels={"x":"–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏","y":"–ö–æ–ª-–≤–æ"},
                                       title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏"), use_container_width=True)

            # --- –æ—Ç—á—ë—Ç ---
            out_path = PROCESS_DIR / f"–æ—Ç—á–µ—Ç_–æ–±—Ä–∞—â–µ–Ω–∏–π_{ts}.xlsx"
            generate_report(out_path, df, unique_df, duplicates_df)
            with open(out_path, "rb") as f:
                st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç (Excel)", f, file_name=out_path.name,
                                   mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
